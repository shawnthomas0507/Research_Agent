{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class Analyst(BaseModel):\n",
    "    affiliation: str=Field(\n",
    "        description=\"Primary affiliation of an analyst.\"\n",
    "    )\n",
    "    name: str=Field(\n",
    "        description=\"Name of the analyst.\"\n",
    "    )\n",
    "    role: str=Field(\n",
    "        description=\"Role of the analyst in the context of the topic.\"\n",
    "    )\n",
    "    description: str=Field(\n",
    "        description=\"Description of analyst focus, concerns and motives.\"\n",
    "    )\n",
    "    @property\n",
    "    def persona(self)->str:\n",
    "        return f\"Name:{self.name}\\nRole: {self.role}\\nAffiliation:{self.affiliation}\\nDescription:{self.description}\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perspectives(BaseModel):\n",
    "    analysts: List[Analyst]=Field(\n",
    "        description=\"comprehensive list of analysts with their roles and affirmations.\"\n",
    "    )\n",
    "\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "     topic: str\n",
    "     max_analysts: int\n",
    "     human_analyst_feedback: str\n",
    "     analysts: List[Analyst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions=\"\"\"You are tasked with creating a set of AI analyst personas.Follow these instructions carefully:\n",
    "1.First, review the research topic:\n",
    "{topic}\n",
    "\n",
    "2.Examine the editorial feedback that has been optionally provided to guide creation of analysts:\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3.Determine the most interesting themes based upon documents or feedback above.\n",
    "\n",
    "4.Pick the top {max_analysts} themes.\n",
    "\n",
    "5.Assign one analyst to each theme.\n",
    "\"\"\"\n",
    "\n",
    "def create_analysts(state:GenerateAnalystsState):\n",
    "    topic=state[\"topic\"]\n",
    "    max_analysts=state[\"max_analysts\"]\n",
    "    human_analyst_feedback=state.get('human_analyst_feedback','')\n",
    "    structured_llm=llm.with_structured_output(Perspectives)\n",
    "    system_message=analyst_instructions.format(topic=topic,human_analyst_feedback=human_analyst_feedback,max_analysts=max_analysts)\n",
    "    analysts=structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate a set of analysts\")])\n",
    "    return {\"analysts\":analysts.analysts}\n",
    "\n",
    "\n",
    "def human_feedback(state:GenerateAnalystsState):\n",
    "    pass\n",
    "\n",
    "def should_continue(state:GenerateAnalystsState):\n",
    "    human_analyst_feedback=state.get('human_analyst_feedback',None)\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    return END\n",
    "\n",
    "builder=StateGraph(GenerateAnalystsState)\n",
    "builder.add_node(\"create_analysts\",create_analysts)\n",
    "builder.add_node(\"human_feedback\",human_feedback)\n",
    "builder.add_edge(START,\"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\",\"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\",should_continue,[\"create_analysts\",END])\n",
    "\n",
    "memory=MemorySaver()\n",
    "graph=builder.compile(interrupt_before=['human_feedback'],checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts=3\n",
    "topic='''Benefits of drinking water'''\n",
    "thread={\"configurable\":{\"thread_id\":\"1\"}}\n",
    "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts},thread,stream_mode=\"values\"):\n",
    "    analysts=event.get('analysts','')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name:{analyst.name}\")\n",
    "            print(f\"Affiliation:{analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None,thread,stream_mode=\"values\"):\n",
    "    analysts=event.get('analysts','')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name:{analyst.name}\")\n",
    "            print(f\"Affiliation:{analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts=final_state.values.get('analysts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name:{analyst.name}\")\n",
    "    print(f\"Affiliation:{analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int\n",
    "    context:Annotated[list,operator.add]\n",
    "    analyst: Analyst\n",
    "    interview: str\n",
    "    sections: list\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str =Field(None,description=\"search query for retrieval\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_instructions=\"\"\"You are an analyst tasked with interviewing an expert to learn a specific topic.\n",
    "Your goal is to boil down to interesting and specific insights related to the topic.\n",
    "\n",
    "1.Interesting: Insights that people find non obvious.\n",
    "2.Specific: Insights that avoid generalities and include examples from the expert.\n",
    "\n",
    "Here is your topic of focus and a set of goals {goals}\n",
    "\n",
    "Begin introducing yourself by using your name that fits your persona, and then ask your question.\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "When you are satisfied with your undersatnding. Complete the interview with a \"Thank you for your help\".\n",
    "Remember to stay in character throughout your response, reflecting your persona and goals provided to you.\n",
    "\"\"\"\n",
    "def generate_question(state: InterviewState):\n",
    "    analyst=state[\"analyst\"]\n",
    "    messages=state[\"messages\"]\n",
    "\n",
    "    system_message=questions_instructions.format(goals=analyst.persona)\n",
    "    question=llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "\n",
    "    return {\"messages\":question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_instructions=SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
    "Your goal is to generate a well structured query for us in retrieval or web search related to the conversation.\n",
    "First analyse the full conversation.\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "Convert this final question into a well structured web search query\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "def search_web(state: InterviewState):\n",
    "    structured_llm=llm.with_structured_output(SearchQuery)\n",
    "    search_query=structured_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "    tavily_search=TavilySearchResults(api_wrapper=tav,max_results=3)\n",
    "    search_docs=tavily_search.invoke(search_query.search_query)\n",
    "    formatted_search_docs=\"\\n\\n---\\n\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in search_docs\n",
    "    ])\n",
    "    return {\"context\":[formatted_search_docs]}\n",
    "\n",
    "def search_wikipedia(state: InterviewState):\n",
    "    structured_llm=llm.with_structured_output(SearchQuery)\n",
    "    search_query=structured_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "    search_docs=WikipediaLoader(query=search_query.search_query,load_max_docs=2).load()\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join([\n",
    "    f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "    for doc in search_docs\n",
    "])\n",
    "\n",
    "    return {\"context\":[formatted_search_docs]}\n",
    "\n",
    "\n",
    "answer_instructions=\"\"\" You are an expert being interviewed by an analyst.\n",
    "Here is analyst area of focus: {goals}.\n",
    "Your goal is to answer a question posed by the interviewer.\n",
    "To answer the question use this context:\n",
    "{context}\n",
    "\n",
    "When answering questions follow these guidelines:\n",
    "1. Use only the information provided in the context.\n",
    "2. Do not make assumptions or introduce external information.\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "4. Include these sources in your answer next to any relevant statements.\n",
    "5. Skip addition of brackets as well as Document source preamble in your citation. \n",
    "\"\"\"\n",
    "\n",
    "def generate_answer(state:InterviewState):\n",
    "    analyst=state[\"analyst\"]\n",
    "    messages=state[\"messages\"]\n",
    "    context=state[\"context\"]\n",
    "    system_message=answer_instructions.format(goals=analyst.persona,context=context)\n",
    "    answer=llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "    answer.name=\"expert\"\n",
    "    return {\"messages\":[answer]}\n",
    "\n",
    "def save_interview(state:InterviewState):\n",
    "    messages=state[\"messages\"]\n",
    "    interview=get_buffer_string(messages)\n",
    "    return {\"interview\":interview}\n",
    "\n",
    "\n",
    "def route_messages(state:InterviewState,name:str='expert'):\n",
    "    messages=state[\"messages\"]\n",
    "    max_num_turns=state.get('max_num_turns',2)\n",
    "\n",
    "    num_responses=len(\n",
    "        [m for m in messages if isinstance(m,AIMessage) and m.name==name]\n",
    "    )\n",
    "\n",
    "    if num_responses>=max_num_turns:\n",
    "        return 'save_interview'\n",
    "    last_question=messages[-2]\n",
    "\n",
    "    if \"Thank you so much for your help\" in last_question.content:\n",
    "        return \"save_interview\"\n",
    "    return \"ask_question\"\n",
    "\n",
    "section_writer_instructions=\"\"\"You are an expert technical writer.\n",
    "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
    "1.Analyse the content of the source documents.\n",
    "Write the report in a proper understandable manner.\n",
    "\"\"\"\n",
    "\n",
    "def write_section(state: InterviewState):\n",
    "    interview=state[\"interview\"]\n",
    "    context=state[\"context\"]\n",
    "    analyst=state[\"analyst\"]\n",
    "    system_message=section_writer_instructions.format(focus=analyst.description)\n",
    "    section=llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")])\n",
    "    return {\"sections\":[section.content]}\n",
    "\n",
    "\n",
    "interview_builder=StateGraph(InterviewState)\n",
    "interview_builder.add_node(\"ask_question\",generate_question)\n",
    "interview_builder.add_node(\"search_web\",search_web)\n",
    "interview_builder.add_node(\"search_wiki\",search_wikipedia)\n",
    "interview_builder.add_node(\"answer_question\",generate_answer)\n",
    "interview_builder.add_node(\"save_interview\",save_interview)\n",
    "interview_builder.add_node(\"write_section\",write_section)\n",
    "\n",
    "\n",
    "interview_builder.add_edge(START,\"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\",\"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\",\"search_wiki\")\n",
    "interview_builder.add_edge(\"search_web\",\"answer_question\")\n",
    "interview_builder.add_edge(\"search_wiki\",\"answer_question\")\n",
    "interview_builder.add_conditional_edges(\"answer_question\",route_messages,['ask_question','save_interview'])\n",
    "interview_builder.add_edge(\"save_interview\",\"write_section\")\n",
    "interview_builder.add_edge(\"write_section\",END)\n",
    "memory=MemorySaver()\n",
    "interview_graph=interview_builder.compile(checkpointer=memory).with_config(run_name=\"conduct_interviews\")\n",
    "display(Image(interview_graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[HumanMessage(content=f\"So you were writing an article on {topic}\")]\n",
    "thread={\"configurable\":{\"thread_id\":\"7\"}}\n",
    "interview=interview_graph.invoke({\"analyst\":analysts[0],\"messages\":messages,\"max_num_turns\":1},thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchGraphstate(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "    sections: Annotated[list,operator.add]\n",
    "    introduction: str\n",
    "    content: str\n",
    "    conclusion: str\n",
    "    final_report: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "def initiate_all_interviews(state:ResearchGraphstate):\n",
    "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    else:\n",
    "        topic=state[\"topic\"]\n",
    "    return [Send(\"conduct_interview\", {\"analyst\": analyst, \"topic\": topic, \"messages\": [HumanMessage(content=f\"So you said you were writing an article on {topic}?\")]}) for analyst in state[\"analysts\"]]\n",
    "\n",
    "report_writer_instructions=\"\"\"You are a technical writer  creating a report on this overall topic:\n",
    "{topic}\n",
    "\n",
    "You have a team of analysts.Each analyst has done 2 things:\n",
    "1.They conducted an interview with an expert on a specific sub topic\n",
    "2.They write up their finding on a memo\n",
    "\n",
    "Your task:\n",
    "1.You will be given a collection of memos.\n",
    "2.Think carefullt about the insights from each memo.\n",
    "3.Consolidate all into a final summary with ideas from all reports.\n",
    "4.It should be a single narrative\n",
    "\n",
    "Here are the memos from your analysts to build your report from:\n",
    "{context}\n",
    "\"\"\"                                                                                \n",
    "\n",
    "def write_report(state: ResearchGraphstate):\n",
    "    sections=state[\"sections\"]\n",
    "    topic=state[\"topic\"]\n",
    "\n",
    "    formatted_sec=\"\\n\\n\".join([f\"{sections} for section in sections\"])\n",
    "\n",
    "    system_message=report_writer_instructions.format(topic=topic,context=formatted_sec)\n",
    "    report=llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"fWrite a report based on these memos\")])\n",
    "    return {\"content\":report.content}     \n",
    "\n",
    "builder=StateGraph(ResearchGraphstate)\n",
    "builder.add_node(\"create_analysts\",create_analysts)\n",
    "builder.add_node(\"human_feedback\",human_feedback)\n",
    "builder.add_node(\"conduct_interview\",interview_builder.compile())\n",
    "builder.add_node(\"write_report\",write_report)\n",
    "\n",
    "builder.add_edge(START,\"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\",\"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\",initiate_all_interviews,[\"create_analysts\",\"conduct_interview\"])\n",
    "builder.add_edge(\"conduct_interview\",\"write_report\")\n",
    "builder.add_edge(\"write_report\",END)\n",
    "\n",
    "memory=MemorySaver()\n",
    "app=builder.compile(interrupt_before=[\"human_feedback\"],checkpointer=memory)\n",
    "display(Image(app.get_graph(xray=1).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts=2\n",
    "topic='''2024 Presidential Election'''\n",
    "thread={\"configurable\":{\"thread_id\":\"11\"}}\n",
    "for event in app.stream({\"topic\":topic,\"max_analysts\":max_analysts},thread,stream_mode=\"values\"):\n",
    "    analysts=event.get('analysts','')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name:{analyst.name}\")\n",
    "            print(f\"Affiliation:{analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(None,thread,stream_mode=\"values\"):\n",
    "    analysts=event.get('analysts','')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name:{analyst.name}\")\n",
    "            print(f\"Affiliation:{analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
